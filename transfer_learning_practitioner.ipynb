{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Carregando as bibliotecas necessárias ao modelo"
      ],
      "metadata": {
        "id": "83pHlD3P_VmT"
      }
    },
    {
      "metadata": {
        "id": "3p-OjhDPYoZm"
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import keras\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import imshow\n",
        "\n",
        "from keras.preprocessing import image\n",
        "# from keras.applications.imagenet_utils import preprocess_input\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Activation\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.models import Model\n",
        "\n",
        "from google.colab import drive\n",
        "from IPython.display import display\n",
        "from ipywidgets import FileUpload, widgets\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VWWN-FPLYoZs"
      },
      "cell_type": "markdown",
      "source": [
        "# 2. Obtendo o conjunto de dados (dataset)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import urllib.request\n",
        "\n",
        "# URL do dataset no GitHub\n",
        "dataset_url = \"https://github.com/jjofilho/transfer-learning-python/raw/main/dataset.zip\"\n",
        "\n",
        "# Nome do arquivo compactado\n",
        "dataset_zip = \"dataset.zip\"\n",
        "\n",
        "# Verifica se o dataset já está disponível\n",
        "if not os.path.exists(\"dataset\"):\n",
        "    print(\"Baixando dataset...\")\n",
        "    urllib.request.urlretrieve(dataset_url, dataset_zip)\n",
        "\n",
        "    # Extraindo o arquivo zip\n",
        "    with zipfile.ZipFile(dataset_zip, 'r') as zip_ref:\n",
        "        zip_ref.extractall(\".\")\n",
        "\n",
        "    print(\"Dataset extraído com sucesso!\")\n",
        "else:\n",
        "    print(\"Dataset já está disponível!\")\n"
      ],
      "metadata": {
        "id": "wnDTSETU_PBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K2ERhVlFYoZy"
      },
      "cell_type": "markdown",
      "source": [
        "# 3. Pré-processamento dos dados das imagens e o vetor entrada"
      ]
    },
    {
      "metadata": {
        "id": "A1T1Joq7YoZz"
      },
      "cell_type": "code",
      "source": [
        "# helper function to load image and return it and input vector\n",
        "def get_image(path):\n",
        "    img = image.load_img(path, target_size=(224, 224))\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x)\n",
        "    return img, x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zUwQ60GGYoZ3"
      },
      "cell_type": "markdown",
      "source": [
        "# 4. Carregando as imagens e identificando o número de classes para o modelo"
      ]
    },
    {
      "metadata": {
        "id": "5nAUr-ooYoZ4"
      },
      "cell_type": "code",
      "source": [
        "data = []\n",
        "for c, category in enumerate(categories):\n",
        "    images = [os.path.join(dp, f) for dp, dn, filenames\n",
        "              in os.walk(category) for f in filenames\n",
        "              if os.path.splitext(f)[1].lower() in ['.jpg','.png','.jpeg']]\n",
        "    for img_path in images:\n",
        "        img, x = get_image(img_path)\n",
        "        data.append({'x':np.array(x[0]), 'y':c})\n",
        "\n",
        "# count the number of classes\n",
        "num_classes = len(categories)\n",
        "print(f'Número de classes no dataset: ', num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "55Rw-ptVYoZ7"
      },
      "cell_type": "markdown",
      "source": [
        "# 5. Definindo uma busca aleatória dos dados\n",
        "Importante: o resultado apresentado do teste é alterado a cada execução da célula"
      ]
    },
    {
      "metadata": {
        "id": "5vGeJK55YoZ8"
      },
      "cell_type": "code",
      "source": [
        "random.shuffle(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OwHqS_NgYoZ_"
      },
      "cell_type": "markdown",
      "source": [
        "# 6. Criando: Treinamento | Validação | Teste (70%, 15%, 15%)"
      ]
    },
    {
      "metadata": {
        "id": "PT9Cuq2rYoaB"
      },
      "cell_type": "code",
      "source": [
        "idx_val = int(train_split * len(data))\n",
        "idx_test = int((train_split + val_split) * len(data))\n",
        "train = data[:idx_val]\n",
        "val = data[idx_val:idx_test]\n",
        "test = data[idx_test:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EsOVhpqcYoaF"
      },
      "cell_type": "markdown",
      "source": [
        "# 7. Classificando os dados\n"
      ]
    },
    {
      "metadata": {
        "id": "vQOGN9kOYoaH"
      },
      "cell_type": "code",
      "source": [
        "x_train, y_train = np.array([t[\"x\"] for t in train]), [t[\"y\"] for t in train]\n",
        "x_val, y_val = np.array([t[\"x\"] for t in val]), [t[\"y\"] for t in val]\n",
        "x_test, y_test = np.array([t[\"x\"] for t in test]), [t[\"y\"] for t in test]\n",
        "print(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vc6W07QVYoaM"
      },
      "cell_type": "markdown",
      "source": [
        "# 8. Pré-processamento dos dados como antes, certificando-se de que sejam float32 e normalizados entre 0 e 1"
      ]
    },
    {
      "metadata": {
        "id": "qnXaiAgJYoaQ"
      },
      "cell_type": "code",
      "source": [
        "# Normalizando os data\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_val = x_val.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "\n",
        "# Convertendo os labels para OneHotVector\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_val = keras.utils.to_categorical(y_val, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ordUucUKYoaS"
      },
      "cell_type": "markdown",
      "source": [
        "# 9. Resumo do projeto até o momento"
      ]
    },
    {
      "metadata": {
        "id": "AcKjxgtyYoaT"
      },
      "cell_type": "code",
      "source": [
        "# Resumo\n",
        "print(\"Carregamento de %d imagens com %d categorias\"%(len(data), num_classes))\n",
        "print(\"Treinamento | Validação | Split Teste: %d, %d, %d\"%(len(x_train), len(x_val), len(x_test)))\n",
        "print(\"Tamanho dos dados treinados: \", x_train.shape)\n",
        "print(\"Tamanho dos labels: \", y_train.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y84SmM2CYoaZ"
      },
      "cell_type": "code",
      "source": [
        "images = [os.path.join(dp, f) for dp, dn, filenames in os.walk(root) for f in filenames if os.path.splitext(f)[1].lower() in ['.jpg','.png','.jpeg']]\n",
        "idx = [int(len(images) * random.random()) for i in range(8)]\n",
        "imgs = [image.load_img(images[i], target_size=(224, 224)) for i in idx]\n",
        "concat_image = np.concatenate([np.asarray(img) for img in imgs], axis=1)\n",
        "plt.figure(figsize=(16,4))\n",
        "plt.imshow(concat_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n2s5qypkYoad"
      },
      "cell_type": "markdown",
      "source": [
        "# 10. Construção da rede neural base"
      ]
    },
    {
      "metadata": {
        "id": "y41GiiYTYoaf"
      },
      "cell_type": "code",
      "source": [
        "# Construindo a Rede Neural\n",
        "model = Sequential()\n",
        "print(\"Input dimensions: \",x_train.shape[1:])\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11. Treinando o modelo"
      ],
      "metadata": {
        "id": "s0PNNr86NEq2"
      }
    },
    {
      "metadata": {
        "id": "CIqHecNAYoaj"
      },
      "cell_type": "code",
      "source": [
        "# Compilando o modelo para usar a função de perda 'categorical_crossentropy' e o otimizador 'adam' (AdaDelta)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=128,\n",
        "                    epochs=10,\n",
        "                    validation_data=(x_val, y_val))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yG0CKOI1Yoao"
      },
      "cell_type": "markdown",
      "source": [
        "# 12. Avaliando a Perda de Validação e a Acurácia de Validação"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gráfico de precisão (accuracy)\n",
        "fig = plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Loss (perda)\n",
        "ax1 = fig.add_subplot(121)\n",
        "ax1.plot(history.history[\"loss\"], label=\"Treinamento\")\n",
        "ax1.plot(history.history[\"val_loss\"], label=\"Validação\")\n",
        "ax1.set_title(\"Perda do Modelo\")\n",
        "ax1.set_xlabel(\"Época\")\n",
        "ax1.set_ylabel(\"Perda\")\n",
        "ax1.legend()\n",
        "ax1.grid(True)\n",
        "\n",
        "# Accuracy (acurácia)\n",
        "ax2 = fig.add_subplot(122)\n",
        "ax2.plot(history.history[\"accuracy\"], label=\"Treinamento\")\n",
        "ax2.plot(history.history[\"val_accuracy\"], label=\"Validação\")\n",
        "ax2.set_title(\"Acurácia do Modelo\")\n",
        "ax2.set_xlabel(\"Época\")\n",
        "ax2.set_ylabel(\"Acurácia\")\n",
        "ax2.legend()\n",
        "ax2.grid(True)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Mz6XyfhZBh-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 13. Avaliação"
      ],
      "metadata": {
        "id": "ZNl05WmKSRcI"
      }
    },
    {
      "metadata": {
        "id": "8Itd5LDAYoav"
      },
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Teste de Perda:', loss)\n",
        "print('Teste da Acurácia:', accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hLXTofcNYoa2"
      },
      "cell_type": "markdown",
      "source": [
        "# 14. Transfer Learning começando com a rede existente"
      ]
    },
    {
      "metadata": {
        "id": "KpUDAbxiYoay"
      },
      "cell_type": "code",
      "source": [
        "vgg = keras.applications.VGG16(weights='imagenet', include_top=True)\n",
        "vgg.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rFL-fLitYoa3"
      },
      "cell_type": "code",
      "source": [
        "# camada de entrada do VGG\n",
        "inp = vgg.input\n",
        "\n",
        "# nova camada softmax com neurônios num_classes\n",
        "new_classification_layer = Dense(num_classes, activation='softmax')\n",
        "\n",
        "# conectando a nova camada à penúltima camada no VGG e faça uma referência a ela\n",
        "out = new_classification_layer(vgg.layers[-4].output)\n",
        "\n",
        "# criando a nova rede entre inp e out\n",
        "model_new = Model(inp, out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MBIp3fbQYoa9"
      },
      "cell_type": "markdown",
      "source": [
        " # 15. Aplicando o Transfer Learning"
      ]
    },
    {
      "metadata": {
        "id": "e_n5A8oGYoa9"
      },
      "cell_type": "code",
      "source": [
        "# Treinando  algumas camadas convolucionais para permitir ajuste fino e mantendo os pesos das demais fixas (congeladas)\n",
        "for l, layer in enumerate(model_new.layers[:-4]):\n",
        "    layer.trainable = False\n",
        "\n",
        "for l, layer in enumerate(model_new.layers[-4:]):\n",
        "    layer.trainable = True\n",
        "\n",
        "model_new.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_new.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8B9G0gC1YobD"
      },
      "cell_type": "markdown",
      "source": [
        "# 16. Conferindo o histórico do modelo após aplicado o Transfer Learning"
      ]
    },
    {
      "metadata": {
        "id": "aDdq71XNYobD"
      },
      "cell_type": "code",
      "source": [
        "history2 = model_new.fit(x_train, y_train,\n",
        "                         batch_size=128,\n",
        "                         epochs=10,\n",
        "                         validation_data=(x_val, y_val))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jPqJ0OM8YobI"
      },
      "cell_type": "markdown",
      "source": [
        "# 17. Apresentando o gráfico da Perda de Validação e Acurácia de Validação,\n",
        "Modelo base, treinado do zero (azul) e o modelo aprendido por transferência (laranja-tracejado)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gráfico com legendas e labels\n",
        "fig = plt.figure(figsize=(16, 4))\n",
        "\n",
        "# Gráfico da Perda de Validação\n",
        "ax1 = fig.add_subplot(121)\n",
        "ax1.plot(history.history[\"val_loss\"], label=\"Modelo 1\", color=\"blue\", linestyle=\"-\")\n",
        "ax1.plot(history2.history[\"val_loss\"], label=\"Modelo 2\", color=\"orange\", linestyle=\"--\")\n",
        "ax1.set_title(\"Perda de Validação\", fontsize=14)\n",
        "ax1.set_xlabel(\"Época\", fontsize=12)\n",
        "ax1.set_ylabel(\"Perda\", fontsize=12)\n",
        "ax1.legend(loc=\"upper right\", fontsize=10)\n",
        "ax1.grid(True)\n",
        "\n",
        "# Gráfico da Acurácia de Validação\n",
        "ax2 = fig.add_subplot(122)\n",
        "ax2.plot(history.history[\"val_accuracy\"], label=\"Modelo 1\", color=\"blue\", linestyle=\"-\")\n",
        "ax2.plot(history2.history[\"val_accuracy\"], label=\"Modelo 2\", color=\"orange\", linestyle=\"--\")\n",
        "ax2.set_title(\"Acurácia de Validação\", fontsize=14)\n",
        "ax2.set_xlabel(\"Época\", fontsize=12)\n",
        "ax2.set_ylabel(\"Acurácia\", fontsize=12)\n",
        "ax2.legend(loc=\"upper right\", fontsize=10)\n",
        "ax2.grid(True)"
      ],
      "metadata": {
        "id": "KfFUsPBcDFNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vXjfVTVIYobM"
      },
      "cell_type": "markdown",
      "source": [
        "# 18. Nova validação no conjunto de teste"
      ]
    },
    {
      "metadata": {
        "id": "zMxC6Pd1YobN"
      },
      "cell_type": "code",
      "source": [
        "loss, accuracy = model_new.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "print('Test loss:', loss)\n",
        "print('Test accuracy:', accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 19. Agora é sua vez de se divertir e aplicar o modelo!\n",
        "\n",
        "A seguir, você pode carregar uma imagem válida, de violão ou guitarra, e aplicar o presente modelo de classificação com redes neurais.\n",
        "\n",
        "Boa diversão!"
      ],
      "metadata": {
        "id": "FBYfBw1qaFav"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_image_external(model, image_path, class_labels):\n",
        "    \"\"\"\n",
        "    Classifica uma imagem utilizando o modelo treinado.\n",
        "\n",
        "    Args:\n",
        "        model: O modelo treinado para a classificação.\n",
        "        image_path: Caminho ou objeto da imagem a ser classificada.\n",
        "        class_labels: Lista com os nomes das classes (ex: ['violao', 'guitarra']).\n",
        "\n",
        "    Returns:\n",
        "        None. Exibe a imagem e a classe prevista.\n",
        "    \"\"\"\n",
        "    # Carregar e preprocessar a imagem\n",
        "    img, x = get_image(image_path)\n",
        "    probabilities = model.predict([x])\n",
        "\n",
        "    # Determinar a classe com maior probabilidade\n",
        "    predicted_class = class_labels[np.argmax(probabilities)]\n",
        "\n",
        "    # Exibir a imagem e o resultado da classificação\n",
        "    plt.imshow(img)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(f\"Predição: {predicted_class}\")\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Probabilidade: {probabilities}\")\n",
        "    print(f\"Classe predita: {predicted_class}\")\n",
        "\n",
        "# Lista de classes do modelo\n",
        "class_labels = [\"guitarra\", \"violão\"]\n",
        "\n",
        "# Função para processar imagem local\n",
        "def upload_image(change):\n",
        "    uploaded_file = next(iter(upload_widget.value.values()))\n",
        "    content = uploaded_file['content']\n",
        "\n",
        "    # Salvar a imagem para processamento\n",
        "    with open(\"temp_image.jpg\", \"wb\") as f:\n",
        "        f.write(content)\n",
        "    classify_image_external(model_new, \"temp_image.jpg\", class_labels)\n",
        "\n",
        "# Função para processar imagem de URL\n",
        "def classify_image_from_url(url):\n",
        "    try:\n",
        "        # Requisição HTTP para a URL\n",
        "        response = requests.get(url)\n",
        "\n",
        "        # Verificação se o conteúdo retornado é válido\n",
        "        if response.status_code == 200 and \"image\" in response.headers[\"Content-Type\"]:\n",
        "            # Abrindo a imagem diretamente\n",
        "            img = Image.open(BytesIO(response.content))\n",
        "            img.save(\"temp_url_image.jpg\")  # Salvar a imagem temporariamente\n",
        "            classify_image_external(model_new, \"temp_url_image.jpg\", class_labels)\n",
        "        else:\n",
        "            print(\"Erro: O link fornecido não retorna uma imagem válida.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao carregar a imagem da URL: {e}\")\n",
        "\n",
        "# Widgets para interação\n",
        "upload_widget = FileUpload(accept='image/*', multiple=False)\n",
        "url_widget = widgets.Text(\n",
        "    value='',\n",
        "    placeholder='Digite a URL da imagem',\n",
        "    description='URL:',\n",
        "    layout=widgets.Layout(width='50%')\n",
        ")\n",
        "button_url = widgets.Button(description=\"Classificar Imagem URL\")\n",
        "output = widgets.Output()\n",
        "\n",
        "def on_button_url_click(b):\n",
        "    with output:\n",
        "        output.clear_output()\n",
        "        classify_image_from_url(url_widget.value)\n",
        "\n",
        "# Conectando os widgets às funções\n",
        "upload_widget.observe(upload_image, names='value')\n",
        "button_url.on_click(on_button_url_click)\n",
        "\n",
        "# Exibir os widgets\n",
        "display(widgets.VBox([\n",
        "    widgets.HTML(\"<h3>Selecione uma Imagem:</h3>\"),\n",
        "    upload_widget,\n",
        "    widgets.HTML(\"<h3>Ou forneça uma URL:</h3>\"),\n",
        "    url_widget,\n",
        "    button_url,\n",
        "    output\n",
        "]))\n"
      ],
      "metadata": {
        "id": "r5oIzHvoFyAv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}